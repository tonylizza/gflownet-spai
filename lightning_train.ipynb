{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/tonylizza/opt/anaconda3/envs/ML2/lib/python3.9/site-packages/pytorch_lightning/trainer/configuration_validator.py:106: UserWarning: You passed in a `val_dataloader` but have no `validation_step`. Skipping val loop.\n",
      "  rank_zero_warn(\"You passed in a `val_dataloader` but have no `validation_step`. Skipping val loop.\")\n",
      "/Users/tonylizza/opt/anaconda3/envs/ML2/lib/python3.9/site-packages/pytorch_lightning/core/optimizer.py:329: RuntimeWarning: The lr scheduler dict contains the key(s) ['monitor'], but the keys will be ignored. You need to call `lr_scheduler.step()` manually in manual optimization.\n",
      "  rank_zero_warn(\n",
      "/Users/tonylizza/opt/anaconda3/envs/ML2/lib/python3.9/site-packages/pytorch_lightning/utilities/model_summary/model_summary.py:411: UserWarning: A layer with UninitializedParameter was found. Thus, the total number of parameters detected may be inaccurate.\n",
      "  warning_cache.warn(\n",
      "\n",
      "  | Name            | Type           | Params\n",
      "---------------------------------------------------\n",
      "0 | forward_policy  | ForwardPolicy  | 2.7 K \n",
      "1 | backward_policy | BackwardPolicy | 2.6 K \n",
      "---------------------------------------------------\n",
      "5.4 K     Trainable params\n",
      "0         Non-trainable params\n",
      "5.4 K     Total params\n",
      "0.021     Total estimated model params size (MB)\n",
      "/Users/tonylizza/opt/anaconda3/envs/ML2/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/Users/tonylizza/opt/anaconda3/envs/ML2/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:1558: PossibleUserWarning: The number of training batches (4) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9011aa063c87498695afbe878120d499",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tonylizza/Documents/Machine_Learning/Thesis_Coding/gflownet-spai/gflownet/dataset.py:39: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /Users/runner/miniforge3/conda-bld/pytorch-recipe_1670284382755/work/torch/csrc/utils/tensor_new.cpp:233.)\n",
      "  ilu_indices = torch.tensor([ilu_matrix.row, ilu_matrix.col], dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 85.27972412109375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tonylizza/opt/anaconda3/envs/ML2/lib/python3.9/site-packages/pytorch_lightning/utilities/data.py:85: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 39. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "  warning_cache.warn(\n",
      "2024-10-08 15:12:28.440695: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 43.57345962524414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tonylizza/opt/anaconda3/envs/ML2/lib/python3.9/site-packages/pytorch_lightning/utilities/data.py:85: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 18. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "  warning_cache.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 128.91253662109375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tonylizza/opt/anaconda3/envs/ML2/lib/python3.9/site-packages/pytorch_lightning/utilities/data.py:85: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 24. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "  warning_cache.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 79.8160400390625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tonylizza/opt/anaconda3/envs/ML2/lib/python3.9/site-packages/pytorch_lightning/utilities/data.py:85: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 20. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "  warning_cache.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 74.73145294189453\n",
      "Loss: 48.40712356567383\n",
      "Loss: 198.37857055664062\n",
      "Loss: 186.78443908691406\n",
      "Loss: 165.31248474121094\n",
      "Loss: 158.16510009765625\n",
      "Loss: 188.43345642089844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=3` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 106.8479995727539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of b_vector: <class 'numpy.ndarray'>\n",
      "0.32812318921093814\n",
      "0.15179589887931275\n",
      "0.10120974737554654\n",
      "0.09827242672107069\n",
      "0.09660496166578185\n",
      "0.09550885211837341\n",
      "0.06930874396518417\n",
      "0.012729815114667175\n",
      "0.0068508800875989794\n",
      "0.0027690650855343533\n",
      "0.0012317148149761203\n",
      "0.000316327188247506\n",
      "0.0001989472706301368\n",
      "9.043720845232405e-05\n",
      "8.449511459155003e-05\n",
      "3.129417134234208e-05\n",
      "1.0424079916612562e-05\n",
      "1.8747002397253028e-06\n",
      "GMRES converged successfully.\n",
      "GMRES no preconditioner\n",
      "0.0026174187636077376\n",
      "0.0021290864012168892\n",
      "0.0019634946844222364\n",
      "0.001879777410405055\n",
      "0.0013779486768492582\n",
      "0.0013719907206318712\n",
      "0.001370507822265031\n",
      "0.0013402971904138018\n",
      "0.0011809522869048574\n",
      "0.0007974278023325054\n",
      "0.0006200569434583073\n",
      "3.33762528525477e-05\n",
      "7.626650324963723e-06\n",
      "1.737371358856771e-06\n",
      "1.7371487746582079e-06\n",
      "1.0534158322314024e-06\n",
      "1.0531935303641418e-06\n",
      "1.0471187475693089e-06\n",
      "8.559369745298563e-08\n",
      "8.292919254468309e-08\n",
      "8.292919256451806e-08\n",
      "8.292919256346775e-08\n",
      "8.292919256341593e-08\n",
      "8.292919255848151e-08\n",
      "8.292919254818495e-08\n",
      "8.292919254073948e-08\n",
      "8.292919253495924e-08\n",
      "8.292919252517903e-08\n",
      "8.292919240010326e-08\n",
      "8.292919237414959e-08\n",
      "GMRES did not converge. Exit code: tensor([30])\n",
      "GMRES orig preconditioner\n",
      "0.0025123120083800246\n",
      "0.001297931812160171\n",
      "0.0012593239661645775\n",
      "0.001203612245089363\n",
      "0.0011418884835165892\n",
      "0.0008577694491620749\n",
      "0.0007678736314236723\n",
      "0.00021786915476449973\n",
      "0.00013661172848290515\n",
      "0.00013414177132113774\n",
      "0.00013409858113688466\n",
      "6.448132849755507e-05\n",
      "2.196246489248173e-05\n",
      "2.065211104948695e-05\n",
      "7.627390789060741e-07\n",
      "5.083082656358819e-07\n",
      "3.5365829506525554e-07\n",
      "2.639139508944992e-07\n",
      "2.3747505507660393e-07\n",
      "1.6718614574791855e-08\n",
      "1.67186143130694e-08\n",
      "1.6718614311972308e-08\n",
      "1.6718614306273474e-08\n",
      "1.6718614222693345e-08\n",
      "1.6718613976474833e-08\n",
      "1.671861397558158e-08\n",
      "1.6718613908319343e-08\n",
      "1.6718613902911335e-08\n",
      "1.671861350464979e-08\n",
      "1.6718605167895796e-08\n",
      "GMRES did not converge. Exit code: tensor([30])\n",
      "GMRES sparse preconditioner\n",
      "0.0018992995669296795\n",
      "0.001443640697277029\n",
      "0.0014433637896623243\n",
      "0.0011169188611795128\n",
      "0.0004692868024720234\n",
      "0.0004048065882683722\n",
      "0.0001616382612330481\n",
      "0.00014383683810886472\n",
      "4.9960089705977594e-05\n",
      "4.9701868110320144e-05\n",
      "4.7131454328442055e-05\n",
      "2.951745867837987e-05\n",
      "1.1363276522201664e-05\n",
      "2.4936387085935083e-06\n",
      "8.420948085174478e-07\n",
      "2.294218493972467e-07\n",
      "2.2687976058390622e-07\n",
      "1.0663183739394176e-07\n",
      "5.125006893901374e-08\n",
      "5.12500662708823e-08\n",
      "5.125006627088164e-08\n",
      "5.125006625448168e-08\n",
      "5.1250066251873975e-08\n",
      "5.1250066249508107e-08\n",
      "5.125006587070886e-08\n",
      "5.1250065497571045e-08\n",
      "5.125006418214325e-08\n",
      "5.125005680089586e-08\n",
      "5.1250025441057464e-08\n",
      "5.124999996052896e-08\n",
      "GMRES did not converge. Exit code: tensor([30])\n",
      "GMRES sparse preconditioner\n",
      "0.0019034966478929008\n",
      "0.00144435218632872\n",
      "0.0014442627520153478\n",
      "0.0011125081384292389\n",
      "0.0006085600790962635\n",
      "0.00048187836312160037\n",
      "0.00018250807021283992\n",
      "0.00013597335545067164\n",
      "9.780432548036709e-05\n",
      "6.280177728838235e-05\n",
      "4.716447786318047e-05\n",
      "2.128178173875302e-05\n",
      "7.007760614667367e-06\n",
      "6.421943094811461e-06\n",
      "3.8537870978581174e-07\n",
      "2.706320897914886e-07\n",
      "2.6178151376012587e-07\n",
      "9.293553384703001e-08\n",
      "9.293553625070872e-08\n",
      "9.293553623649616e-08\n",
      "9.293553617342096e-08\n",
      "9.293553598145352e-08\n",
      "9.293553584010848e-08\n",
      "9.293553582290748e-08\n",
      "9.293552333831766e-08\n",
      "9.293550862881174e-08\n",
      "9.293521280419716e-08\n",
      "9.293505953484378e-08\n",
      "9.293503313514623e-08\n",
      "9.289382584410238e-08\n",
      "GMRES did not converge. Exit code: tensor([30])\n",
      "GMRES sparse preconditioner\n",
      "0.0019337153674543472\n",
      "0.0015065511228515803\n",
      "0.0013807573740202217\n",
      "0.001316197974879575\n",
      "0.00043254053701759275\n",
      "0.00014261902075585043\n",
      "0.00014261674149273205\n",
      "0.0001356009379569568\n",
      "0.00013435362470728176\n",
      "0.00011266183263202666\n",
      "2.1105552116783514e-05\n",
      "1.2888044489275656e-05\n",
      "1.2171042402688143e-05\n",
      "7.828009958763971e-07\n",
      "6.672267727421402e-07\n",
      "1.952738883401215e-07\n",
      "1.727833689168946e-07\n",
      "9.393029124711792e-08\n",
      "1.5626455347733825e-08\n",
      "1.562645534697779e-08\n",
      "1.562645534697739e-08\n",
      "1.5626455346049828e-08\n",
      "1.562645534549312e-08\n",
      "1.5626455345324305e-08\n",
      "1.5626455345089154e-08\n",
      "1.562645532523937e-08\n",
      "1.5626455322027626e-08\n",
      "1.5626455309575517e-08\n",
      "1.5626455309570478e-08\n",
      "1.5626455232627044e-08\n",
      "GMRES did not converge. Exit code: tensor([30])\n",
      "GMRES sparse preconditioner\n",
      "0.0024862651928367215\n",
      "0.0019260010219438357\n",
      "0.0019117850848480312\n",
      "0.0018230893992373953\n",
      "0.0017697941305696466\n",
      "0.0016041394337359851\n",
      "0.0016040813148673508\n",
      "0.0015156595476141974\n",
      "0.0015130030192750305\n",
      "0.0003786149977565699\n",
      "5.992039107846334e-05\n",
      "5.6621006278327026e-05\n",
      "5.391215644702427e-05\n",
      "5.3874027193862084e-05\n",
      "6.5473037871689e-06\n",
      "3.1502994490976258e-06\n",
      "2.733183288605512e-06\n",
      "2.732969497910579e-06\n",
      "2.705567145571754e-06\n",
      "1.7387862957224949e-06\n",
      "1.7387862612480631e-06\n",
      "1.7387862593102733e-06\n",
      "1.738786257697052e-06\n",
      "1.738786257691032e-06\n",
      "1.7387862488823308e-06\n",
      "1.7387862407912982e-06\n",
      "1.7387862404428416e-06\n",
      "1.7387861650964348e-06\n",
      "1.7387861631853125e-06\n",
      "1.7387856823489222e-06\n",
      "GMRES did not converge. Exit code: tensor([30])\n",
      "GMRES sparse preconditioner\n",
      "0.0017421950579924164\n",
      "0.0015247337760028032\n",
      "0.00131508046775742\n",
      "0.0010356160790119609\n",
      "0.0007615802998473576\n",
      "0.000753113190826569\n",
      "0.0001568428722669264\n",
      "0.00012617497846109747\n",
      "9.105863738624907e-05\n",
      "7.698561651419628e-05\n",
      "8.776154567064443e-06\n",
      "2.8077463768428917e-06\n",
      "2.803607886392834e-06\n",
      "2.7909827846799555e-06\n",
      "2.3583594685040476e-07\n",
      "1.0620286384695366e-07\n",
      "1.0087203199209267e-07\n",
      "8.256067299120739e-08\n",
      "8.2405727626792e-08\n",
      "1.0244369211746743e-08\n",
      "1.0244368882749303e-08\n",
      "1.0244368880962128e-08\n",
      "1.0244368880920542e-08\n",
      "1.0244368880524637e-08\n",
      "1.0244368879433138e-08\n",
      "1.024436887694474e-08\n",
      "1.0244368867844986e-08\n",
      "1.0244368862790408e-08\n",
      "1.0244368784015328e-08\n",
      "1.0244368580025136e-08\n",
      "GMRES did not converge. Exit code: tensor([30])\n",
      "GMRES sparse preconditioner\n",
      "0.0017605065654340696\n",
      "0.0016376462884552545\n",
      "0.0014306611085638085\n",
      "0.0012161124126632763\n",
      "0.001200658197840195\n",
      "0.0011340232796344493\n",
      "0.00101662332040965\n",
      "0.0009538399476533006\n",
      "0.0007341596368795492\n",
      "0.0006145251413367514\n",
      "0.00031761787102568904\n",
      "9.761409151047676e-05\n",
      "7.250636630301532e-05\n",
      "3.6873521884401625e-05\n",
      "1.9233590508310215e-05\n",
      "7.5998483501302516e-06\n",
      "8.846762785409286e-07\n",
      "8.190291581465073e-07\n",
      "7.114988307637539e-07\n",
      "2.1371023600142975e-07\n",
      "2.1371023459489257e-07\n",
      "2.137102345917735e-07\n",
      "2.1371023458740994e-07\n",
      "2.137102345753196e-07\n",
      "2.137102345681012e-07\n",
      "2.1371023455028136e-07\n",
      "2.1371023453627496e-07\n",
      "2.1371023453458055e-07\n",
      "2.137102345240163e-07\n",
      "2.137102344675565e-07\n",
      "GMRES did not converge. Exit code: tensor([30])\n",
      "GMRES sparse preconditioner\n",
      "0.0014835479766832217\n",
      "0.0014703450766457447\n",
      "0.0014364928522166297\n",
      "0.0012365672939652\n",
      "0.0012248918672382503\n",
      "0.0011375319946077922\n",
      "0.001098583483578972\n",
      "0.001036098407608685\n",
      "0.001026665482621179\n",
      "0.0010260937837263569\n",
      "0.0003123020674786306\n",
      "0.00014040069805736977\n",
      "0.00013899721713433877\n",
      "4.1814746546107204e-05\n",
      "4.1289589041045016e-05\n",
      "1.3504832809351625e-05\n",
      "1.3431094292444249e-05\n",
      "1.323883687262781e-05\n",
      "5.8591572455971866e-06\n",
      "7.721113094080111e-07\n",
      "7.721113072906488e-07\n",
      "7.721113043836183e-07\n",
      "7.721112896606506e-07\n",
      "7.72111284858377e-07\n",
      "7.721112759015609e-07\n",
      "7.721112736969005e-07\n",
      "7.721112690062347e-07\n",
      "7.721112508165324e-07\n",
      "7.721111974468358e-07\n",
      "7.721111066156096e-07\n",
      "GMRES did not converge. Exit code: tensor([30])\n",
      "GMRES sparse preconditioner\n",
      "0.0018926614617317502\n",
      "0.0014433285037450318\n",
      "0.0014426440364134826\n",
      "0.0011228192685384972\n",
      "0.0006085505945033745\n",
      "0.00044667762137542754\n",
      "0.00018540988518863063\n",
      "0.00013025789242743113\n",
      "5.1015850274417754e-05\n",
      "5.041976542301983e-05\n",
      "4.949166232162056e-05\n",
      "2.9192728519915033e-05\n",
      "5.640939869424809e-06\n",
      "3.367400491484121e-06\n",
      "9.986902123534077e-07\n",
      "2.923550654333626e-07\n",
      "1.9116177402725572e-07\n",
      "1.49095609668232e-07\n",
      "5.001855850057555e-08\n",
      "5.00185574333077e-08\n",
      "5.0018557427752837e-08\n",
      "5.001855736378527e-08\n",
      "5.0018557347102045e-08\n",
      "5.001855733572574e-08\n",
      "5.0018556612439003e-08\n",
      "5.001855657933165e-08\n",
      "5.001853618363765e-08\n",
      "5.001851938981701e-08\n",
      "5.001851718070387e-08\n",
      "5.0018497778813305e-08\n",
      "GMRES did not converge. Exit code: tensor([30])\n",
      "GMRES sparse preconditioner\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [02:44<00:00, 164.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0018596139799814144\n",
      "0.0014546924286096886\n",
      "0.0014497698232682312\n",
      "0.0012109551680721568\n",
      "0.0012075646138968456\n",
      "0.00041494823604836976\n",
      "0.0003621342752547848\n",
      "0.00017107750017166984\n",
      "0.00016179961698728953\n",
      "0.00012588131469256993\n",
      "0.0001258041398136911\n",
      "2.179952846110148e-05\n",
      "1.2066486272375322e-05\n",
      "5.662182798870154e-06\n",
      "2.576114498451562e-06\n",
      "1.0306394517435261e-06\n",
      "1.030547216064838e-06\n",
      "7.709222053922616e-07\n",
      "7.255070846063271e-08\n",
      "7.255070111641441e-08\n",
      "7.255070111335487e-08\n",
      "7.255070111004304e-08\n",
      "7.255070107285591e-08\n",
      "7.255070106883367e-08\n",
      "7.255070050739301e-08\n",
      "7.255070015463215e-08\n",
      "7.255069965124993e-08\n",
      "7.255069961285546e-08\n",
      "7.255069541014708e-08\n",
      "7.255068603354489e-08\n",
      "GMRES did not converge. Exit code: tensor([30])\n",
      "GMRES sparse preconditioner\n",
      "Logged validation results after training epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning import Trainer\n",
    "from policy import ForwardPolicy, BackwardPolicy\n",
    "from gflownet.gflownet import GFlowNet\n",
    "from gflownet.dataset import MatrixDataModule\n",
    "\n",
    "def main():\n",
    "    # Initialize the data module\n",
    "    matrix_dir = 'data/small_ILU'  # Replace with your actual directory\n",
    "    data_module = MatrixDataModule(matrix_directory=matrix_dir, batch_size=1)\n",
    "                                   \n",
    "    node_features = -1\n",
    "    input_dim = 1\n",
    "    hidden_dim = 4\n",
    "    max_num_actions = 500\n",
    "    back_action_size = -1\n",
    "    #Initialize the model\n",
    "    forward_policy = ForwardPolicy(node_features=node_features, hidden_dim=hidden_dim, max_num_actions=max_num_actions)\n",
    "    backward_policy = BackwardPolicy(input_dim=input_dim, hidden_dim=hidden_dim, max_num_actions=max_num_actions)\n",
    "\n",
    "    logger = TensorBoardLogger(\"tb_logs\", name=\"gflownet\")\n",
    "\n",
    "    model = GFlowNet(forward_policy=forward_policy, backward_policy=backward_policy, no_sampling_batch=2, lr=0.00002)\n",
    "\n",
    "    # Initialize the PyTorch Lightning Trainer\n",
    "    trainer = Trainer(max_epochs=3, logger=logger)  # You can modify trainer arguments as needed\n",
    "\n",
    "    # Train the model\n",
    "    trainer.fit(model, data_module)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
