{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/tonylizza/opt/anaconda3/envs/ML_new/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:68: You passed in a `val_dataloader` but have no `validation_step`. Skipping val loop.\n",
      "/Users/tonylizza/opt/anaconda3/envs/ML_new/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n",
      "/Users/tonylizza/opt/anaconda3/envs/ML_new/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py:316: The lr scheduler dict contains the key(s) ['monitor'], but the keys will be ignored. You need to call `lr_scheduler.step()` manually in manual optimization.\n",
      "/Users/tonylizza/opt/anaconda3/envs/ML_new/lib/python3.12/site-packages/pytorch_lightning/utilities/model_summary/model_summary.py:477: The total number of parameters detected may be inaccurate because the model contains an instance of `UninitializedParameter`. To get an accurate number, set `self.example_input_array` in your LightningModule.\n",
      "\n",
      "  | Name            | Type           | Params | Mode \n",
      "-----------------------------------------------------------\n",
      "0 | forward_policy  | ForwardPolicy  | 900 K  | train\n",
      "1 | backward_policy | BackwardPolicy | 900 K  | train\n",
      "-----------------------------------------------------------\n",
      "1.8 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.8 M     Total params\n",
      "7.201     Total estimated model params size (MB)\n",
      "17        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/Users/tonylizza/opt/anaconda3/envs/ML_new/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
      "/Users/tonylizza/opt/anaconda3/envs/ML_new/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (4) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/4 [00:00<?, ?it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tonylizza/Documents/Machine_Learning/Thesis_Coding/gflownet-spai/gflownet/dataset.py:39: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /Users/runner/miniforge3/conda-bld/libtorch_1719361045918/work/torch/csrc/utils/tensor_new.cpp:277.)\n",
      "  ilu_indices = torch.tensor([ilu_matrix.row, ilu_matrix.col], dtype=torch.long)\n",
      "/Users/tonylizza/Documents/Machine_Learning/Thesis_Coding/gflownet-spai/gflownet/utils.py:418: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at /Users/runner/miniforge3/conda-bld/libtorch_1719361045918/work/aten/src/ATen/SparseCsrTensorImpl.cpp:55.)\n",
      "  product = torch.mm(updated_matrix, original_matrix)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Actions: 151\n",
      "tensor([212.9842], dtype=torch.float64)\n",
      "Num Actions: 151\n",
      "tensor([405.3284], dtype=torch.float64)\n",
      "Padded Forward Probs torch.Size([2, 75, 1, 151])\n",
      "Loss: 114.50151062011719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tonylizza/opt/anaconda3/envs/ML_new/lib/python3.12/site-packages/pytorch_lightning/utilities/data.py:78: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 39. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  25%|██▌       | 1/4 [00:25<01:16,  0.04it/s, v_num=13]Num Actions: 119\n",
      "tensor([128.1882], dtype=torch.float64)\n",
      "Num Actions: 119\n",
      "tensor([475.9112], dtype=torch.float64)\n",
      "Padded Forward Probs torch.Size([2, 59, 1, 119])\n",
      "Loss: 153.8465118408203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tonylizza/opt/anaconda3/envs/ML_new/lib/python3.12/site-packages/pytorch_lightning/utilities/data.py:78: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 18. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  50%|█████     | 2/4 [00:45<00:45,  0.04it/s, v_num=13]Num Actions: 130\n",
      "tensor([13.8789], dtype=torch.float64)\n",
      "Num Actions: 130\n",
      "tensor([294.6423], dtype=torch.float64)\n",
      "Padded Forward Probs torch.Size([2, 52, 1, 130])\n",
      "Loss: 165.34445190429688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tonylizza/opt/anaconda3/envs/ML_new/lib/python3.12/site-packages/pytorch_lightning/utilities/data.py:78: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 24. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  75%|███████▌  | 3/4 [00:59<00:19,  0.05it/s, v_num=13]Num Actions: 297\n",
      "[Sampled 100 actions] CPU Memory Usage: 648.71 MB; VMS: 36067.50 MB\n",
      "100\n",
      "tensor([250.3973], dtype=torch.float64)\n",
      "Num Actions: 297\n",
      "tensor([74.4130], dtype=torch.float64)\n",
      "Padded Forward Probs torch.Size([2, 148, 1, 297])\n",
      "Loss: 144.34507751464844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tonylizza/opt/anaconda3/envs/ML_new/lib/python3.12/site-packages/pytorch_lightning/utilities/data.py:78: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 20. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:   0%|          | 0/4 [00:00<?, ?it/s, v_num=13]        Num Actions: 119\n",
      "tensor([401.7176], dtype=torch.float64)\n",
      "Num Actions: 119\n",
      "tensor([378.4015], dtype=torch.float64)\n",
      "Padded Forward Probs torch.Size([2, 59, 1, 119])\n",
      "Loss: 34.40227127075195\n",
      "Epoch 1:  25%|██▌       | 1/4 [00:37<01:52,  0.03it/s, v_num=13]Num Actions: 297\n",
      "[Sampled 100 actions] CPU Memory Usage: 749.33 MB; VMS: 36024.70 MB\n",
      "100\n",
      "tensor([250.3690], dtype=torch.float64)\n",
      "Num Actions: 297\n",
      "[Sampled 100 actions] CPU Memory Usage: 761.24 MB; VMS: 36054.70 MB\n",
      "100\n",
      "tensor([250.3076], dtype=torch.float64)\n",
      "Padded Forward Probs torch.Size([2, 148, 1, 297])\n",
      "Loss: 29.8472843170166\n",
      "Epoch 1:  50%|█████     | 2/4 [02:29<02:29,  0.01it/s, v_num=13]Num Actions: 130\n",
      "tensor([383.6275], dtype=torch.float64)\n",
      "Num Actions: 130\n",
      "tensor([416.3603], dtype=torch.float64)\n",
      "Padded Forward Probs torch.Size([2, 64, 1, 130])\n",
      "Loss: 35.270687103271484\n",
      "Epoch 1:  75%|███████▌  | 3/4 [03:31<01:10,  0.01it/s, v_num=13]Num Actions: 151\n",
      "tensor([297.8815], dtype=torch.float64)\n",
      "Num Actions: 151\n",
      "tensor([22.9964], dtype=torch.float64)\n",
      "Padded Forward Probs torch.Size([2, 55, 1, 151])\n",
      "Loss: 171.28114318847656\n",
      "Epoch 1: 100%|██████████| 4/4 [04:06<00:00,  0.02it/s, v_num=13]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=2` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 4/4 [04:06<00:00,  0.02it/s, v_num=13]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of b_vector: <class 'numpy.ndarray'>\n",
      "GMRES converged successfully.\n",
      "GMRES no preconditioner\n",
      "GMRES did not converge. Exit code: tensor([30])\n",
      "GMRES orig preconditioner\n",
      "GMRES did not converge. Exit code: tensor([30])\n",
      "GMRES sparse preconditioner\n",
      "GMRES did not converge. Exit code: tensor([30])\n",
      "GMRES sparse preconditioner\n",
      "GMRES did not converge. Exit code: tensor([30])\n",
      "GMRES sparse preconditioner\n",
      "GMRES did not converge. Exit code: tensor([30])\n",
      "GMRES sparse preconditioner\n",
      "GMRES did not converge. Exit code: tensor([30])\n",
      "GMRES sparse preconditioner\n",
      "GMRES did not converge. Exit code: tensor([30])\n",
      "GMRES sparse preconditioner\n",
      "GMRES did not converge. Exit code: tensor([30])\n",
      "GMRES sparse preconditioner\n",
      "GMRES did not converge. Exit code: tensor([30])\n",
      "GMRES sparse preconditioner\n",
      "GMRES did not converge. Exit code: tensor([30])\n",
      "GMRES sparse preconditioner\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [09:19<00:00, 559.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GMRES did not converge. Exit code: tensor([30])\n",
      "GMRES sparse preconditioner\n",
      "Validation results saved to validation_results_20241022135859.csv\n",
      "Logged validation results after training epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name            | Type           | Params | Mode \n",
      "-----------------------------------------------------------\n",
      "0 | forward_policy  | ForwardPolicy  | 900 K  | train\n",
      "1 | backward_policy | BackwardPolicy | 900 K  | train\n",
      "-----------------------------------------------------------\n",
      "1.8 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.8 M     Total params\n",
      "7.201     Total estimated model params size (MB)\n",
      "17        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/4 [00:00<?, ?it/s] Num Actions: 151\n",
      "tensor([366.6802], dtype=torch.float64)\n",
      "Num Actions: 151\n",
      "tensor([350.8768], dtype=torch.float64)\n",
      "Padded Forward Probs torch.Size([2, 75, 1, 151])\n",
      "Loss: 46.79605484008789\n",
      "Epoch 0:  25%|██▌       | 1/4 [02:11<06:35,  0.01it/s, v_num=0]Num Actions: 119\n",
      "tensor([381.9548], dtype=torch.float64)\n",
      "Num Actions: 119\n",
      "tensor([378.8410], dtype=torch.float64)\n",
      "Padded Forward Probs torch.Size([2, 59, 1, 119])\n",
      "Loss: 35.65675735473633\n",
      "Epoch 0:  50%|█████     | 2/4 [03:51<03:51,  0.01it/s, v_num=0]Num Actions: 130\n",
      "tensor([419.3176], dtype=torch.float64)\n",
      "Num Actions: 130\n",
      "tensor([293.0187], dtype=torch.float64)\n",
      "Padded Forward Probs torch.Size([2, 64, 1, 130])\n",
      "Loss: 92.41976165771484\n",
      "Epoch 0:  75%|███████▌  | 3/4 [05:15<01:45,  0.01it/s, v_num=0]Num Actions: 297\n",
      "[Sampled 100 actions] CPU Memory Usage: 666.93 MB; VMS: 36115.82 MB\n",
      "100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x1109b9790>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/tonylizza/opt/anaconda3/envs/ML_new/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 775, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "\n",
      "KeyboardInterrupt: \n"
     ]
    }
   ],
   "source": [
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning import Trainer\n",
    "from policy import ForwardPolicy, BackwardPolicy\n",
    "from gflownet.gflownet import GFlowNet\n",
    "from gflownet.dataset import MatrixDataModule\n",
    "import itertools\n",
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from gflownet.gflownet import GFlowNet\n",
    "from gflownet.dataset import MatrixDataModule\n",
    "\n",
    "\n",
    "def run_experiment(hyperparams):\n",
    "    matrix_dir = 'data/medium_ILU'\n",
    "    data_module = MatrixDataModule(matrix_directory=matrix_dir, batch_size=1)\n",
    "\n",
    "    forward_policy = ForwardPolicy(node_features=hyperparams['node_features'], hidden_dim=hyperparams['hidden_dim'], max_num_actions=hyperparams['max_num_actions'])\n",
    "    backward_policy = BackwardPolicy(input_dim=hyperparams['input_dim'], hidden_dim=hyperparams['hidden_dim'], max_num_actions=hyperparams['max_num_actions'])\n",
    "\n",
    "    model = GFlowNet(forward_policy=forward_policy, backward_policy=backward_policy, no_sampling_batch=hyperparams['no_sampling_batch'], lr=hyperparams['lr'], schedule_patience=hyperparams['schedule_patience'])\n",
    "\n",
    "    logger = TensorBoardLogger(\"tb_logs\", name=f\"gflownet_lr_{hyperparams['lr']}_epochs_{hyperparams['number_epoch']}_sampling_{hyperparams['no_sampling_batch']}_patience_{hyperparams['schedule_patience']}\")\n",
    "\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor=\"train_loss\", mode=\"min\", patience=10),\n",
    "        ModelCheckpoint(monitor=\"train_loss\", save_top_k=3, mode=\"min\")\n",
    "    ]\n",
    "\n",
    "    trainer = pl.Trainer(max_epochs=hyperparams['number_epoch'], logger=logger, callbacks=callbacks)\n",
    "    trainer.fit(model, data_module)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Define hyperparameters space\n",
    "    learning_rates = [2e-4, 7e-5, 2e-5]\n",
    "    number_epochs = [2, 3] #Change to 50, 100 after testing\n",
    "    no_sampling_batches = [2, 4] #Change to 4, 8, 16 after testing\n",
    "    schedule_patience = [5, 10] \n",
    "\n",
    "    # Create hyperparameter combinations\n",
    "    hyperparams_combinations = list(itertools.product(learning_rates, number_epochs, no_sampling_batches, schedule_patience))\n",
    "\n",
    "    # Run experiments for each combination\n",
    "    for lr, number_epoch, no_sampling_batch, patience in hyperparams_combinations:\n",
    "        hyperparams = {\n",
    "            'lr': lr,\n",
    "            'number_epoch': number_epoch,\n",
    "            'no_sampling_batch': no_sampling_batch,\n",
    "            'hidden_dim': 4,\n",
    "            'node_features': -1,\n",
    "            'input_dim': 1,\n",
    "            'max_num_actions': 180000,\n",
    "            'schedule_patience': patience\n",
    "        }\n",
    "        run_experiment(hyperparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
