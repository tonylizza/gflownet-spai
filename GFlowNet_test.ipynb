{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.functional import one_hot\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n",
    "from preconditioner import PreconditionerEnv\n",
    "from policy import ForwardPolicy, BackwardPolicy\n",
    "from gflownet.gflownet import GFlowNet\n",
    "from gflownet.utils import sparse_one_hot\n",
    "from gflownet.utils import trajectory_balance_loss, market_matrix_to_sparse_tensor\n",
    "import psutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_memory_usage(stage: str):\n",
    "    process = psutil.Process()\n",
    "    mem_info = process.memory_info()\n",
    "    print(f\"[{stage}] CPU Memory Usage: {mem_info.rss / (1024 ** 2):.2f} MB\")\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"[{stage}] GPU Memory Usage: {torch.cuda.memory_allocated() / (1024 ** 2):.2f} MB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_path = '../LF10/LF10.mtx'  # Update this with your file path\n",
    "batch_size = 3\n",
    "num_epochs = 10\n",
    "lr = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Before Loading Initial Matrix] CPU Memory Usage: 204.77 MB\n",
      "[After Loading Initial Matrix] CPU Memory Usage: 205.41 MB\n"
     ]
    }
   ],
   "source": [
    "log_memory_usage(\"Before Loading Initial Matrix\")\n",
    "\n",
    "# Load the initial matrix from a file\n",
    "initial_matrix = market_matrix_to_sparse_tensor(matrix_path)\n",
    "matrix_size = initial_matrix.size(0)\n",
    "\n",
    "log_memory_usage(\"After Loading Initial Matrix\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([82])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the environment and policies\n",
    "env = PreconditionerEnv(matrix_size=matrix_size, initial_matrix=initial_matrix)\n",
    "env.data.edge_attr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "node_features = -1  # Assuming each node has a single feature, can be adjusted\n",
    "hidden_dim = 8\n",
    "forward_policy = ForwardPolicy(node_features=node_features, hidden_dim=hidden_dim, num_actions=env.num_actions)\n",
    "#forward_policy = ForwardPolicy(in_channels=node_features, hidden_channels=hidden_dim, out_channels=env.num_actions)\n",
    "backward_policy = BackwardPolicy(matrix_size=matrix_size, num_actions=env.num_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([82])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.data.edge_attr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_gradients(model):\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.requires_grad:\n",
    "            if param.grad is not None:\n",
    "                print(f\"{name}: {param.grad.norm()}\")\n",
    "            else:\n",
    "                print(f\"{name}: No gradient\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[After Model Initialization] CPU Memory Usage: 241.88 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Active States [tensor(indices=tensor([[ 0,  1,  2,  1,  3,  4,  2,  3,  4,  3,  5,  6,  4,  5,\n",
      "                         6,  5,  7,  8,  6,  7,  8,  7,  9, 10,  8,  9, 10,  9,\n",
      "                        11, 12, 10, 11, 12, 11, 13, 14, 12, 13, 14, 13, 15, 16,\n",
      "                        14, 15, 16, 15, 17, 16, 17, 17,  0,  0,  1,  1,  2,  2,\n",
      "                         3,  3,  4,  4,  5,  5,  6,  6,  7,  7,  8,  8,  9,  9,\n",
      "                        10, 10, 11, 11, 12, 12, 13, 13, 14, 14, 15, 16],\n",
      "                       [ 0,  0,  0,  1,  1,  1,  2,  2,  2,  3,  3,  3,  4,  4,\n",
      "                         4,  5,  5,  5,  6,  6,  6,  7,  7,  7,  8,  8,  8,  9,\n",
      "                         9,  9, 10, 10, 10, 11, 11, 11, 12, 12, 12, 13, 13, 13,\n",
      "                        14, 14, 14, 15, 15, 16, 16, 17,  1,  2,  3,  4,  3,  4,\n",
      "                         5,  6,  5,  6,  7,  8,  7,  8,  9, 10,  9, 10, 11, 12,\n",
      "                        11, 12, 13, 14, 13, 14, 15, 16, 15, 16, 17, 17]]),\n",
      "       values=tensor([ 3.5345e+00, -4.7715e+02,  1.7672e+00,  1.7178e+05,\n",
      "                      -8.5888e+04,  4.7715e+02,  7.0690e+00, -4.7715e+02,\n",
      "                       1.7672e+00,  1.7178e+05, -8.5888e+04,  4.7715e+02,\n",
      "                       7.0690e+00, -4.7715e+02,  1.7672e+00,  1.7178e+05,\n",
      "                      -8.5888e+04,  4.7715e+02,  7.0690e+00, -4.7715e+02,\n",
      "                       1.7672e+00,  1.7178e+05, -8.5888e+04,  4.7715e+02,\n",
      "                       7.0690e+00, -4.7715e+02,  1.7672e+00,  1.7178e+05,\n",
      "                      -8.5888e+04,  4.7715e+02,  7.0690e+00, -4.7715e+02,\n",
      "                       1.7672e+00,  1.7178e+05, -8.5888e+04,  4.7715e+02,\n",
      "                       7.0690e+00, -4.7715e+02,  1.7672e+00,  1.7178e+05,\n",
      "                      -8.5888e+04,  4.7715e+02,  7.0690e+00, -4.7715e+02,\n",
      "                       1.7672e+00,  1.7178e+05,  4.7715e+02,  7.0690e+00,\n",
      "                       1.7672e+00,  3.5345e+00, -4.7715e+02,  1.7672e+00,\n",
      "                      -8.5888e+04,  4.7715e+02, -4.7715e+02,  1.7672e+00,\n",
      "                      -8.5888e+04,  4.7715e+02, -4.7715e+02,  1.7672e+00,\n",
      "                      -8.5888e+04,  4.7715e+02, -4.7715e+02,  1.7672e+00,\n",
      "                      -8.5888e+04,  4.7715e+02, -4.7715e+02,  1.7672e+00,\n",
      "                      -8.5888e+04,  4.7715e+02, -4.7715e+02,  1.7672e+00,\n",
      "                      -8.5888e+04,  4.7715e+02, -4.7715e+02,  1.7672e+00,\n",
      "                      -8.5888e+04,  4.7715e+02, -4.7715e+02,  1.7672e+00,\n",
      "                       4.7715e+02,  1.7672e+00]),\n",
      "       size=(18, 18), nnz=82, dtype=torch.float64, layout=torch.sparse_coo), tensor(indices=tensor([[ 0,  1,  2,  1,  3,  4,  2,  3,  4,  3,  5,  6,  4,  5,\n",
      "                         6,  5,  7,  8,  6,  7,  8,  7,  9, 10,  8,  9, 10,  9,\n",
      "                        11, 12, 10, 11, 12, 11, 13, 14, 12, 13, 14, 13, 15, 16,\n",
      "                        14, 15, 16, 15, 17, 16, 17, 17,  0,  0,  1,  1,  2,  2,\n",
      "                         3,  3,  4,  4,  5,  5,  6,  6,  7,  7,  8,  8,  9,  9,\n",
      "                        10, 10, 11, 11, 12, 12, 13, 13, 14, 14, 15, 16],\n",
      "                       [ 0,  0,  0,  1,  1,  1,  2,  2,  2,  3,  3,  3,  4,  4,\n",
      "                         4,  5,  5,  5,  6,  6,  6,  7,  7,  7,  8,  8,  8,  9,\n",
      "                         9,  9, 10, 10, 10, 11, 11, 11, 12, 12, 12, 13, 13, 13,\n",
      "                        14, 14, 14, 15, 15, 16, 16, 17,  1,  2,  3,  4,  3,  4,\n",
      "                         5,  6,  5,  6,  7,  8,  7,  8,  9, 10,  9, 10, 11, 12,\n",
      "                        11, 12, 13, 14, 13, 14, 15, 16, 15, 16, 17, 17]]),\n",
      "       values=tensor([ 3.5345e+00, -4.7715e+02,  1.7672e+00,  1.7178e+05,\n",
      "                      -8.5888e+04,  4.7715e+02,  7.0690e+00, -4.7715e+02,\n",
      "                       1.7672e+00,  1.7178e+05, -8.5888e+04,  4.7715e+02,\n",
      "                       7.0690e+00, -4.7715e+02,  1.7672e+00,  1.7178e+05,\n",
      "                      -8.5888e+04,  4.7715e+02,  7.0690e+00, -4.7715e+02,\n",
      "                       1.7672e+00,  1.7178e+05, -8.5888e+04,  4.7715e+02,\n",
      "                       7.0690e+00, -4.7715e+02,  1.7672e+00,  1.7178e+05,\n",
      "                      -8.5888e+04,  4.7715e+02,  7.0690e+00, -4.7715e+02,\n",
      "                       1.7672e+00,  1.7178e+05, -8.5888e+04,  4.7715e+02,\n",
      "                       7.0690e+00, -4.7715e+02,  1.7672e+00,  1.7178e+05,\n",
      "                      -8.5888e+04,  4.7715e+02,  7.0690e+00, -4.7715e+02,\n",
      "                       1.7672e+00,  1.7178e+05,  4.7715e+02,  7.0690e+00,\n",
      "                       1.7672e+00,  3.5345e+00, -4.7715e+02,  1.7672e+00,\n",
      "                      -8.5888e+04,  4.7715e+02, -4.7715e+02,  1.7672e+00,\n",
      "                      -8.5888e+04,  4.7715e+02, -4.7715e+02,  1.7672e+00,\n",
      "                      -8.5888e+04,  4.7715e+02, -4.7715e+02,  1.7672e+00,\n",
      "                      -8.5888e+04,  4.7715e+02, -4.7715e+02,  1.7672e+00,\n",
      "                      -8.5888e+04,  4.7715e+02, -4.7715e+02,  1.7672e+00,\n",
      "                      -8.5888e+04,  4.7715e+02, -4.7715e+02,  1.7672e+00,\n",
      "                      -8.5888e+04,  4.7715e+02, -4.7715e+02,  1.7672e+00,\n",
      "                       4.7715e+02,  1.7672e+00]),\n",
      "       size=(18, 18), nnz=82, dtype=torch.float64, layout=torch.sparse_coo), tensor(indices=tensor([[ 0,  1,  2,  1,  3,  4,  2,  3,  4,  3,  5,  6,  4,  5,\n",
      "                         6,  5,  7,  8,  6,  7,  8,  7,  9, 10,  8,  9, 10,  9,\n",
      "                        11, 12, 10, 11, 12, 11, 13, 14, 12, 13, 14, 13, 15, 16,\n",
      "                        14, 15, 16, 15, 17, 16, 17, 17,  0,  0,  1,  1,  2,  2,\n",
      "                         3,  3,  4,  4,  5,  5,  6,  6,  7,  7,  8,  8,  9,  9,\n",
      "                        10, 10, 11, 11, 12, 12, 13, 13, 14, 14, 15, 16],\n",
      "                       [ 0,  0,  0,  1,  1,  1,  2,  2,  2,  3,  3,  3,  4,  4,\n",
      "                         4,  5,  5,  5,  6,  6,  6,  7,  7,  7,  8,  8,  8,  9,\n",
      "                         9,  9, 10, 10, 10, 11, 11, 11, 12, 12, 12, 13, 13, 13,\n",
      "                        14, 14, 14, 15, 15, 16, 16, 17,  1,  2,  3,  4,  3,  4,\n",
      "                         5,  6,  5,  6,  7,  8,  7,  8,  9, 10,  9, 10, 11, 12,\n",
      "                        11, 12, 13, 14, 13, 14, 15, 16, 15, 16, 17, 17]]),\n",
      "       values=tensor([ 3.5345e+00, -4.7715e+02,  1.7672e+00,  1.7178e+05,\n",
      "                      -8.5888e+04,  4.7715e+02,  7.0690e+00, -4.7715e+02,\n",
      "                       1.7672e+00,  1.7178e+05, -8.5888e+04,  4.7715e+02,\n",
      "                       7.0690e+00, -4.7715e+02,  1.7672e+00,  1.7178e+05,\n",
      "                      -8.5888e+04,  4.7715e+02,  7.0690e+00, -4.7715e+02,\n",
      "                       1.7672e+00,  1.7178e+05, -8.5888e+04,  4.7715e+02,\n",
      "                       7.0690e+00, -4.7715e+02,  1.7672e+00,  1.7178e+05,\n",
      "                      -8.5888e+04,  4.7715e+02,  7.0690e+00, -4.7715e+02,\n",
      "                       1.7672e+00,  1.7178e+05, -8.5888e+04,  4.7715e+02,\n",
      "                       7.0690e+00, -4.7715e+02,  1.7672e+00,  1.7178e+05,\n",
      "                      -8.5888e+04,  4.7715e+02,  7.0690e+00, -4.7715e+02,\n",
      "                       1.7672e+00,  1.7178e+05,  4.7715e+02,  7.0690e+00,\n",
      "                       1.7672e+00,  3.5345e+00, -4.7715e+02,  1.7672e+00,\n",
      "                      -8.5888e+04,  4.7715e+02, -4.7715e+02,  1.7672e+00,\n",
      "                      -8.5888e+04,  4.7715e+02, -4.7715e+02,  1.7672e+00,\n",
      "                      -8.5888e+04,  4.7715e+02, -4.7715e+02,  1.7672e+00,\n",
      "                      -8.5888e+04,  4.7715e+02, -4.7715e+02,  1.7672e+00,\n",
      "                      -8.5888e+04,  4.7715e+02, -4.7715e+02,  1.7672e+00,\n",
      "                      -8.5888e+04,  4.7715e+02, -4.7715e+02,  1.7672e+00,\n",
      "                      -8.5888e+04,  4.7715e+02, -4.7715e+02,  1.7672e+00,\n",
      "                       4.7715e+02,  1.7672e+00]),\n",
      "       size=(18, 18), nnz=82, dtype=torch.float64, layout=torch.sparse_coo)]\n",
      "Actions Active tensor([[154],\n",
      "        [114],\n",
      "        [ 95]])\n",
      "Actions Within Update: tensor([[[154]],\n",
      "\n",
      "        [[114]],\n",
      "\n",
      "        [[ 95]]])\n",
      "Actions[0] shape: 1\n",
      "S[idx] 0 NNZ: 81\n",
      "probs log shape: torch.Size([3, 1, 325])\n",
      "just_finished shape: tensor([False, False, False])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "stack expects each tensor to be equal size, but got [1, 324] at entry 0 and [18, 18] at entry 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 24\u001b[0m\n\u001b[1;32m     21\u001b[0m s0 \u001b[38;5;241m=\u001b[39m [initial_matrix\u001b[38;5;241m.\u001b[39mclone() \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(batch_size)]\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m#s0 = one_hot(torch.zeros(batch_size).long(), env.state_dim).float()\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Sample final states and log information\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m s, log \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample_states\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_log\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Calculate the trajectory balance loss\u001b[39;00m\n\u001b[1;32m     27\u001b[0m loss \u001b[38;5;241m=\u001b[39m trajectory_balance_loss(log\u001b[38;5;241m.\u001b[39mtotal_flow,\n\u001b[1;32m     28\u001b[0m                                 log\u001b[38;5;241m.\u001b[39mrewards,\n\u001b[1;32m     29\u001b[0m                                 log\u001b[38;5;241m.\u001b[39mfwd_probs,\n\u001b[1;32m     30\u001b[0m                                 log\u001b[38;5;241m.\u001b[39mback_probs)\n",
      "File \u001b[0;32m~/Documents/Machine_Learning/Thesis_Coding/gflownet-spai/gflownet/gflownet.py:142\u001b[0m, in \u001b[0;36mGFlowNet.sample_states\u001b[0;34m(self, s0, return_log)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mS[idx] \u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m NNZ: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00ms[idx]\u001b[38;5;241m.\u001b[39m_nnz()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_log:\n\u001b[0;32m--> 142\u001b[0m     \u001b[43mlog\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprobs_all\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactions_all\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdone\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;66;03m# Identify terminating actions and update the done tensor\u001b[39;00m\n\u001b[1;32m    145\u001b[0m terminated \u001b[38;5;241m=\u001b[39m (actions_active \u001b[38;5;241m==\u001b[39m (probs_all\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Ensure terminated is a 1D tensor\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Machine_Learning/Thesis_Coding/gflownet-spai/gflownet/log.py:62\u001b[0m, in \u001b[0;36mLog.log\u001b[0;34m(self, s, probs, actions, done)\u001b[0m\n\u001b[1;32m     52\u001b[0m active_clone \u001b[38;5;241m=\u001b[39m active\u001b[38;5;241m.\u001b[39mclone()\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m#print(f\"Active Clone Shape: {active_clone.shape}\")\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;66;03m#print(f\"Active Clone: {active_clone}\")\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     60\u001b[0m \n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# Store the updated state as a stacked tensor\u001b[39;00m\n\u001b[0;32m---> 62\u001b[0m states \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43ms\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_dense\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_traj\u001b[38;5;241m.\u001b[39mappend(states)        \n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m#fwd_probs = torch.ones(actions.shape[0], probs.shape[2])\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [1, 324] at entry 0 and [18, 18] at entry 1"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Initialize the GFlowNet model\n",
    "model = GFlowNet(forward_policy, backward_policy, env)\n",
    "opt = Adam(model.parameters(), lr=lr)\n",
    "\n",
    "log_memory_usage(\"After Model Initialization\")\n",
    "\n",
    "report_data = pd.DataFrame(columns=['epoch', 'num_actions', 'loss', 'reward'])\n",
    "\n",
    "detailed_report_data = pd.DataFrame(columns=['epoch', 'sample_number', 'num_actions', 'loss', 'reward'])\n",
    "\n",
    "for epoch in (p := tqdm(range(num_epochs))):\n",
    "   #log_memory_usage(f\"Start of Epoch {epoch}\")\n",
    "\n",
    "    model.train()\n",
    "    #opt.zero_grad()\n",
    "\n",
    "    # Initialize the starting states\n",
    "    initial_indices = torch.zeros(batch_size).long()\n",
    "    #s0 = [sparse_one_hot(initial_indices[i:i+1], env.state_dim).float() for i in range(batch_size)]\n",
    "    s0 = [initial_matrix.clone() for _ in range(batch_size)]\n",
    "    #s0 = one_hot(torch.zeros(batch_size).long(), env.state_dim).float()\n",
    "    # Sample final states and log information\n",
    "    s, log = model.sample_states(s0, return_log=True)\n",
    "    \n",
    "    # Calculate the trajectory balance loss\n",
    "    loss = trajectory_balance_loss(log.total_flow,\n",
    "                                    log.rewards,\n",
    "                                    log.fwd_probs,\n",
    "                                    log.back_probs)\n",
    "    \n",
    "    #print(f\"log.total_flow {log.total_flow}\")\n",
    "    #print(f\"log.rewards {log.rewards}\")\n",
    "    #print(f\"log.fwd_probs {log.fwd_probs}\")\n",
    "    #print(f\"log.back_probs {log.back_probs}\")\n",
    "    #print(f\"log._actions shape {len(log._actions)}\")\n",
    "    #print(f\"Loss Calculation: {loss}\")\n",
    "    # Backpropagation and optimization step\n",
    "    loss.backward()\n",
    "    #check_gradients(model)\n",
    "    opt.step()\n",
    "    #named_params = model.named_parameters()\n",
    "    opt.zero_grad()\n",
    "\n",
    "    #Capture data\n",
    "    total_length = len(log._actions)\n",
    "    report_data = report_data.append({'epoch': epoch, 'num_actions': total_length, 'loss': loss.item(), 'reward': log.rewards}, ignore_index=True)\n",
    "\n",
    "        # Capture data for each sample in the batch\n",
    "    for sample_id in range(batch_size):\n",
    "        sum_actions = log._actions.t()[sample_id]\n",
    "        mask_actions = sum_actions != -1\n",
    "        num_actions = mask_actions.sum()\n",
    "        reward = log.rewards[sample_id].item() if isinstance(log.rewards, torch.Tensor) else log.rewards[sample_id]\n",
    "        detailed_report_data = detailed_report_data.append({\n",
    "            'epoch': epoch,\n",
    "            'sample_number': sample_id + 1,  # Sample number within the batch/epoch\n",
    "            'num_actions': num_actions.item(),\n",
    "            'loss': loss.item(),\n",
    "            'reward': reward\n",
    "        }, ignore_index=True)\n",
    "    \n",
    "    if epoch % 100 == 0:\n",
    "       tqdm.write(f\"Epoch {epoch} Loss: {loss.item():.3f}, Num_Actions {total_length}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log._actions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_data.to_csv('training_log.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detailed_report_data.to_csv('detailed_training_log.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "# Extract the data\n",
    "epochs = report_data['epoch'].values\n",
    "num_actions = report_data['num_actions'].values\n",
    "losses = report_data['loss'].values\n",
    "\n",
    "# Extract the data\n",
    "epochs = report_data['epoch'].values\n",
    "num_actions = report_data['num_actions'].values\n",
    "losses = report_data['loss'].values\n",
    "\n",
    "# Create the 3D scatter plot\n",
    "fig = go.Figure(data=[go.Scatter3d(\n",
    "    x=epochs,\n",
    "    y=num_actions,\n",
    "    z=losses,\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        size=5,\n",
    "        color=losses,\n",
    "        colorscale='Viridis',\n",
    "        opacity=0.8\n",
    "    ),\n",
    "    text=[f'Epoch: {e}<br>Num Actions: {n}<br>Loss: {l}' for e, n, l in zip(epochs, num_actions, losses)],\n",
    "    hoverinfo='text'\n",
    ")])\n",
    "\n",
    "# Update the layout\n",
    "fig.update_layout(\n",
    "    scene=dict(\n",
    "        xaxis=dict(\n",
    "            title='Epoch',\n",
    "            range=[0, max(epochs) * 1.1]  # Extend the range slightly beyond the max epoch\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            title='Number of Actions'\n",
    "        ),\n",
    "        zaxis=dict(\n",
    "            title='Loss'\n",
    "        )\n",
    "    ),\n",
    "    width=1000,\n",
    "    height=800\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the data\n",
    "epochs = report_data['epoch'].values\n",
    "losses = report_data['loss'].values\n",
    "\n",
    "# Create the 2D scatter plot\n",
    "fig = go.Figure(data=go.Scatter(\n",
    "    x=epochs,\n",
    "    y=losses,\n",
    "    mode='lines+markers',\n",
    "    marker=dict(\n",
    "        size=5,\n",
    "        color='blue'\n",
    "    ),\n",
    "    text=[f'Epoch: {e}<br>Loss: {l}' for e, l in zip(epochs, losses)],\n",
    "    hoverinfo='text'\n",
    "))\n",
    "\n",
    "# Update the layout\n",
    "fig.update_layout(\n",
    "    xaxis=dict(\n",
    "        title='Epoch'\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title='Loss'\n",
    "    ),\n",
    "    width=1000,\n",
    "    height=600,\n",
    "    title='Epoch vs Loss'\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "\n",
    "# Extract the data\n",
    "epochs = report_data['epoch'].values.reshape(-1, 1)\n",
    "losses = report_data['loss'].values\n",
    "\n",
    "# Perform linear regression\n",
    "reg = LinearRegression().fit(epochs, losses)\n",
    "slope = reg.coef_[0]\n",
    "intercept = reg.intercept_\n",
    "\n",
    "# Calculate the regression line\n",
    "regression_line = reg.predict(epochs)\n",
    "\n",
    "# Create the 2D scatter plot\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add the original data\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=report_data['epoch'],\n",
    "    y=report_data['loss'],\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        size=5,\n",
    "        color='blue'\n",
    "    ),\n",
    "    name='Loss',\n",
    "    text=[f'Epoch: {e}<br>Loss: {l}' for e, l in zip(report_data['epoch'], report_data['loss'])],\n",
    "    hoverinfo='text'\n",
    "))\n",
    "\n",
    "# Add the regression line\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=report_data['epoch'],\n",
    "    y=regression_line,\n",
    "    mode='lines',\n",
    "    line=dict(\n",
    "        color='red'\n",
    "    ),\n",
    "    name='Regression Line'\n",
    "))\n",
    "\n",
    "# Update the layout\n",
    "fig.update_layout(\n",
    "    xaxis=dict(\n",
    "        title='Epoch'\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title='Loss'\n",
    "    ),\n",
    "    width=1000,\n",
    "    height=600,\n",
    "    title=f'Epoch vs Loss (Slope: {slope:.4f})'\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()\n",
    "\n",
    "# Print the slope to determine the trend\n",
    "print(f\"The slope of the regression line is {slope:.4f}\")\n",
    "if slope < 0:\n",
    "    print(\"The values are trending down.\")\n",
    "elif slope > 0:\n",
    "    print(\"The values are trending up.\")\n",
    "else:\n",
    "    print(\"The values are constant.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log._actions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check for duplicates across columns\n",
    "def find_column_duplicates(tensor, check_value=None):\n",
    "    num_columns = tensor.size(1)\n",
    "    duplicates = {}\n",
    "    check_value_duplicates = {}\n",
    "    \n",
    "    for col in range(num_columns):\n",
    "        seen = set()\n",
    "        col_duplicates = set()\n",
    "        for row in range(tensor.size(0)):\n",
    "            value = tensor[row, col].item()\n",
    "            if value in seen:\n",
    "                col_duplicates.add(value)\n",
    "            seen.add(value)\n",
    "        \n",
    "        if col_duplicates:\n",
    "            duplicates[col] = col_duplicates\n",
    "        \n",
    "        if check_value is not None and check_value in seen:\n",
    "            check_value_duplicates[col] = check_value in col_duplicates\n",
    "    \n",
    "    return duplicates, check_value_duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates, is_negative_one_duplicate = find_column_duplicates(log._actions, check_value=-1)\n",
    "print(\"Duplicate values by column:\", duplicates)\n",
    "print(\"Is -1 a duplicate in each column:\", is_negative_one_duplicate)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample and plot final states\n",
    "s0 = one_hot(torch.zeros(10**4).long(), env.state_dim).float()\n",
    "s = model.sample_states(s0, return_log=False)\n",
    "# Implement your plot function or use another way to visualize the results\n",
    "# plot(s, env, matrix_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
